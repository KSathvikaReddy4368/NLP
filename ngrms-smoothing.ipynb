{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1737107-cf1b-4443-994b-2e6b7a2a5b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram: ('the', 'fox')\n",
      "Smoothed Probability: 0.14285714285714285\n",
      "N-gram: ('the',)\n",
      "Smoothed Probability: 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "\n",
    "def n_grams(text, n):\n",
    "    tokens = nltk.word_tokenize(text.lower())  # Tokenize and lowercase\n",
    "    return list(nltk.ngrams(tokens, n))\n",
    "\n",
    "def count_n_grams(corpus, n):\n",
    "\n",
    "    counts = defaultdict(lambda: defaultdict(int))  # For n-grams and their contexts\n",
    "    for sentence in corpus:\n",
    "      for ngram in n_grams(sentence, n):\n",
    "        context = ngram[:-1] # the n-1 gram context\n",
    "        token = ngram[-1] # the last word of n-gram\n",
    "        counts[tuple(context)][token] += 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "def smoothed_probability(ngram, counts, n, vocabulary_size, smoothing_factor=1):\n",
    "\n",
    "    context = ngram[:-1]\n",
    "    token = ngram[-1]\n",
    "\n",
    "    if n == 1: # unigram case\n",
    "        numerator = counts[()][token] + smoothing_factor\n",
    "        denominator = sum(counts[()].values()) + smoothing_factor * vocabulary_size\n",
    "    else: # n-gram case\n",
    "        numerator = counts[tuple(context)][token] + smoothing_factor\n",
    "        denominator = sum(counts[tuple(context)].values()) + smoothing_factor * vocabulary_size\n",
    "        \n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def main():\n",
    "    corpus = [\n",
    "        \"The quick brown fox jumps over the lazy dog.\",\n",
    "        \"The brown fox is quick.\",\n",
    "        \"The lazy dog is slow.\",\n",
    "        \"The fox jumps.\"\n",
    "    ]\n",
    "\n",
    "    vocabulary = set()\n",
    "    for sentence in corpus:\n",
    "        for token in nltk.word_tokenize(sentence.lower()):\n",
    "            vocabulary.add(token)\n",
    "    vocabulary_size = len(vocabulary)\n",
    "\n",
    "    n = 2  # Example: bigrams\n",
    "    counts = count_n_grams(corpus, n)\n",
    "\n",
    "    ngram_to_check = (\"the\", \"fox\")\n",
    "    probability = smoothed_probability(ngram_to_check, counts, n, vocabulary_size, smoothing_factor=0.5) # Example smoothing factor\n",
    "\n",
    "    print(f\"N-gram: {ngram_to_check}\")\n",
    "    print(f\"Smoothed Probability: {probability}\")\n",
    "\n",
    "    ngram_to_check = (\"the\",) # unigram\n",
    "    probability = smoothed_probability(ngram_to_check, counts, 1, vocabulary_size, smoothing_factor=0.5) # Example smoothing factor\n",
    "\n",
    "    print(f\"N-gram: {ngram_to_check}\")\n",
    "    print(f\"Smoothed Probability: {probability}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efacaab8-7d90-4938-a1d0-8c2b1b9b57cf",
   "metadata": {},
   "source": [
    "import collections\n",
    "import re\n",
    "def generate_ngrams(text, n):\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    ngrams = zip(*[words[i:] for i in range(n)])\n",
    "    return [' '.join(ngram) for ngram in ngrams]\n",
    "def laplace_smoothing(ngrams, n):\n",
    "    ngram_counts = collections.Counter(ngrams)\n",
    "    vocab_size = len(set(ngrams))\n",
    "    smoothed_ngrams = {}\n",
    "    total_ngrams = sum(ngram_counts.values())\n",
    "    for ngram, count in ngram_counts.items():\n",
    "        smoothed_ngrams[ngram] = (count + 1) / (total_ngrams + vocab_size)\n",
    "    return smoothed_ngrams\n",
    "def main():\n",
    "    text = input(\"Enter a sentence: \")\n",
    "    n = int(input(\"Enter the value of n for n-grams: \"))\n",
    "    ngrams = generate_ngrams(text, n)\n",
    "    smoothed_ngrams = laplace_smoothing(ngrams, n)\n",
    "    print(\"Smoothed n-grams probabilities:\")\n",
    "    for ngram, prob in smoothed_ngrams.items():\n",
    "        print(f\"{ngram}: {prob}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
